# -------------------------
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# -------------------------
import ast, boto3, os, random
from decimal import Decimal
from openai import OpenAI
from PyPDF2 import PdfReader
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd
import streamlit as st


# -------------------------
# å¤–éƒ¨ã¨ã®æ¥ç¶š
# -------------------------
# å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”¨æ„ã™ã‚‹é–¢æ•°
def launch_client():
    openai_api_key = os.environ.get('OPENAI_API_KEY')
    aws_access_key = os.environ.get('AWS_ACCESS_KEY')
    aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')
    aws_region = os.environ.get('AWS_REGION')
    client = OpenAI(api_key=openai_api_key)
    dynamodb = boto3.resource('dynamodb', region_name=aws_region, aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_access_key)
    return client, dynamodb


# -------------------------
# DynamoDB
# -------------------------
# ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def read_from_dynamodb(dynamodb, table_name):
    table = dynamodb.Table(table_name)
    data = []
    response = table.scan()
    data.extend(response['Items'])
    while 'LastEvaluatedKey' in response:
        response = table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])
        data.extend(response['Items'])
    df = pd.DataFrame(data)
    return df

# ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æŒ‡å®šã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã™ã‚‹é–¢æ•°
def delete_item(dynamodb, table_name, partition_key_name, partition_key):
    table = dynamodb.Table(table_name)
    response = table.delete_item(
        Key={
            partition_key_name: partition_key
        }
    )
    return response

# ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã™ã‚‹é–¢æ•°
def delete_all_items(dynamodb, table_name, partition_key_name):
    # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    df = read_from_dynamodb(dynamodb, table_name)
    # å„ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‰Šé™¤ã™ã‚‹
    for index, row in df.iterrows():
        delete_item(dynamodb, table_name, partition_key_name, row[partition_key_name])

# ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€é–¢æ•°
def write_to_dynamodb(dynamodb, df, table_name):
    table = dynamodb.Table(table_name)
    # DataFrameå†…ã®æ•°å€¤ã‚’DynamoDBãŒå¯¾å¿œã—ã¦ã„ã‚‹å‹ã«å¤‰æ›
    df = df.replace(np.nan, 0)
    df = df.applymap(lambda x: Decimal(x) if isinstance(x, (int, float)) else x)
    for i in range(len(df)):
        item = df.iloc[i].to_dict()
        table.put_item(Item=item)


# -------------------------
# ãƒ™ã‚¯ãƒˆãƒ«
# -------------------------
# æ–‡ç« ã‚’ãƒ™ã‚¯ãƒˆãƒ«å¤‰æ›ã™ã‚‹é–¢æ•°
def get_embedding(client, text, model='text-embedding-ada-002'):
   if pd.isnull(text):
       return np.array([])
   text = text.replace('\n', ' ')
   response = client.embeddings.create(input=[text], model=model)
   return np.array(response.data[0].embedding)

# æœ€è¿‘å‚æ¢ç´¢
def nearest_neighbor_search(client, query, df, partition_key_name):
    query_embedded = get_embedding(client, query)
    df_name = df[[partition_key_name, 'name_embedded']].dropna()
    df_description = df[[partition_key_name, 'description_embedded']].dropna()
    df_name = df_name.rename(columns={'name_embedded': 'embedded'})
    df_description = df_description.rename(columns={'description_embedded': 'embedded'})
    # DataFrameã‚’é€£çµ
    df_combined = pd.concat([df_name, df_description], ignore_index=True)
    # é¡ä¼¼åº¦ã¨IDã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    similarities_and_ids = []
    for _, row in df_combined.iterrows():
        similarity = cosine_similarity([row['embedded']], [query_embedded])[0][0]
        similarities_and_ids.append((similarity, row[partition_key_name]))
    # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
    similarities_and_ids.sort(reverse=True)
    # ä¸Šä½2ã¤ã®ç•°ãªã‚‹IDã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã™
    top_ids = []
    for similarity, id in similarities_and_ids:
        if id not in top_ids:
            top_ids.append(id)
            if len(top_ids) == 2:
                break
    # IDã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
    top_df = df[df[partition_key_name].isin(top_ids)]
    return top_df

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å†…å®¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹é–¢æ•°
def process_dataframe(df, client):
    # nameã¨descriptionã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    df['name_embedded'] = df['name'].apply(lambda x: get_embedding(client, x).tolist())
    df['description_embedded'] = df['description'].apply(lambda x: get_embedding(client, x).tolist())
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
    df = convert_df_to_string(df)
    return df


# -------------------------
# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
# -------------------------
# strã‚’floatã«å¤‰æ›ã™ã‚‹é–¢æ•°
def convert_string_to_float_list(s):
    if pd.isnull(s):
        return np.nan
    else:
        return [float(i) for i in ast.literal_eval(s)]

# æ–‡å­—åˆ—å‹ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’floatã®ãƒªã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹é–¢æ•°
def convert_df_embeddings(df, columns=['name_embedded', 'description_embedded']):
    for column in columns:
        if column in df.columns:
            df[column] = df[column].apply(convert_string_to_float_list)
    return df

# floatã®ãƒªã‚¹ãƒˆã‚’strã«å¤‰æ›ã™ã‚‹é–¢æ•°
def convert_float_list_to_string(l):
    if l is np.nan:
        return None
    else:
        return str(l)

# floatã®ãƒªã‚¹ãƒˆã‚’strã«å¤‰æ›ã™ã‚‹é–¢æ•°ã‚’é©ç”¨ã™ã‚‹é–¢æ•°
def convert_df_to_string(df, columns=['name_embedded', 'description_embedded']):
    for column in columns:
        if column in df.columns:
            df[column] = df[column].apply(convert_float_list_to_string)
    return df

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã«å¤‰æ›ã™ã‚‹é–¢æ•°
def df_to_markdown(df):
    markdown_str = ""
    for i, row in df.iterrows():
        if pd.notna(row['name']) and pd.notna(row['description']):
            markdown_str += f"# ã€Œ**{row['name']}**ã€ã«ã¤ã„ã¦ã®è¿½åŠ æƒ…å ±\n"
            markdown_str += f"## èª¬æ˜\n{row['description']}\n"
            markdown_str += "## è©³ç´°\n"
            if pd.notna(row['address']):
                markdown_str += f"- ä½æ‰€: {row['address']}\n"
            if pd.notna(row['access']):
                markdown_str += f"- ã‚¢ã‚¯ã‚»ã‚¹: {row['access']}\n"
            if pd.notna(row['phone']):
                markdown_str += f"- é›»è©±ç•ªå·: {row['phone']}\n"
            if pd.notna(row['url']):
                markdown_str += f"- URL: [{row['name']}]({row['url']})\n"
            if pd.notna(row['strong_point_from_review']):
                markdown_str += "## é­…åŠ›\n"
                points = row['strong_point_from_review'].split(', ')
                if len(points) > 3:
                    points = random.sample(points, 3)
                for point in points:
                    markdown_str += f"- {point.strip()}\n"
            markdown_str += "\n"
    return markdown_str


# -------------------------
# ãã®ä»–
# -------------------------
# è³ªå•æ–‡ã‚’ã‚‚ã¨ã«AIã«è¿½åŠ ã™ã‚‹é©åˆ‡ãªæƒ…å ±ã‚’æ–‡å­—åˆ—ã§è¿”ã™é–¢æ•°
def get_knowledge(client, query, df, partition_key_name='id'):
    df = nearest_neighbor_search(client, query, df, partition_key_name)
    knowledge = df_to_markdown(df)
    return knowledge

# ã‚¨ãƒ©ãƒ¼ã‚’ãŠçŸ¥ã‚‰ã›ã™ã‚‹é–¢æ•°
def show_fail_toast(message=None):
    if message is not None:
        st.toast(message, icon='ğŸ˜±')
    else:
        messages = [
            "ãŠã£ã¨ã€ä½•ã‹ãŒãŠã‹ã—ã„ã‚ˆã†ã§ã™ã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚",
            "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã§ã‚‚å¤§ä¸ˆå¤«ã€ã“ã‚Œã¯ãŸã ã®æ°—ã®ã›ã„ã®ã¯ãšã§ã™ã€‚",
            "ã†ãƒ¼ã‚“ã€ä½•ã‹ãŒã†ã¾ãã„ã‹ãªã‹ã£ãŸã‚ˆã†ã§ã™ã€‚å†åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚",
            "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã§ã‚‚å¿ƒé…ã—ãªã„ã§ã€‚",
            "ä¸å¹¸ãªã“ã¨ã«ã€ä½•ã‹ãŒé–“é•ã£ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚"
        ]
        st.toast(random.choice(messages), icon='ğŸ˜±')

# æˆåŠŸã‚’ãŠçŸ¥ã‚‰ã›ã™ã‚‹é–¢æ•°
def show_success_toast(message=None):
    if message is not None:
        st.toast(message, icon='ğŸ‰')
    else:
        messages = [
            "ç´ æ™´ã‚‰ã—ã„ï¼æ“ä½œã¯æˆåŠŸã—ã¾ã—ãŸã€‚",
            "ã‚„ã£ãŸã­ï¼å…¨ã¦ãŒé †èª¿ã«é€²ã‚“ã§ã„ã¾ã™ã€‚",
            "å®Œç’§ï¼ç´ æ™´ã‚‰ã—ã„ä»•äº‹ãŒã§ãã¾ã—ãŸã€‚",
            "ãŠã‚ã§ã¨ã†ï¼æ“ä½œã¯æˆåŠŸã—ã¾ã—ãŸã€‚",
            "ã™ã”ã„ï¼ã‚„ã‚Šé‚ã’ã¾ã—ãŸã€‚"
        ]
        st.toast(random.choice(messages), icon='ğŸ‰')

# 10%ã§é¢¨èˆ¹ã‚’å‡ºã™é–¢æ•°
def deco_balloons(probability=0.1):
    if random.random() < probability:
        st.balloons()
        show_success_toast('ã‚ã€é¢¨èˆ¹ãŒé£›ã‚“ã§ãã¾ã—ãŸï¼')

# 10%ã§é›ªã‚’é™ã‚‰ã›ã‚‹é–¢æ•°
def deco_snow(min_probability=0.1, max_probability=0.2):
    random_value = random.random()
    if min_probability <= random_value < max_probability:
        st.snow()
        show_success_toast('ã‚“ï¼Ÿé›ªãŒé™ã‚Šå§‹ã‚ãŸã¿ãŸã„ã§ã™ã­â€¦')

# é¢¨èˆ¹ã¨é›ªã®ã©ã¡ã‚‰ã‹ã‚’ãã‚Œãã‚Œ10%ã§å‡ºã™é–¢æ•°
def deco():
    deco_balloons()
    deco_snow()

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã‚’ã‚¯ãƒªã‚¢ã—ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°
def reload():
    st.cache_resource.clear()
    st.session_state.clear()
    st.experimental_rerun()

# ãƒœã‚¿ãƒ³çŠ¶æ…‹ã‚’å«ã‚ã¦å…¨ã¦ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°
def all_reload(button_state):
    st.cache_resource.clear()
    st.session_state.clear()
    st.session_state[button_state] = False
    st.experimental_rerun()

# ãƒœã‚¿ãƒ³ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–ã‚’è¡Œã†é–¢æ•°
def init_session(button_state, button_label):
    if button_state not in st.session_state:
        st.session_state[button_state] = False
    if st.button(button_label):
        st.session_state[button_state] = True

# PDFã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def read_from_pdf(uploaded_file, id):
    pdf = PdfReader(uploaded_file)
    text = ''
    for page in pdf.pages:
        text += page.extract_text()
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰'.pdf'æ‹¡å¼µå­ã‚’å‰Šé™¤
    file_name, _ = os.path.splitext(uploaded_file.name)
    df = pd.DataFrame({
        'name': [file_name],
        'description': [text],
        'url': [''],
        'id': [id]
    })
    return df
